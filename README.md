# Solar
## A Complete Paper On Music Analysis and the Nature of Human Cognition

---
---

  > I dedicate this work to my family, my father, my mother, and my brother, for giving me unconditional love and support throughout all my efforts, to Sir David Gilmour and his loving family for being an example of excellence and for brining so much joy in my life with their music and poetry, to all my music teachers for enlightening me, to all my friends for believing in my words, and to every being who enchants me with beauty.

---
---

### Preamble

At some level of influence during listening, musical changes only elicit rises and falls. Then, comes forth memory. As music is the most powerful form of experience available in our plane of existence taking us to heights traversable only in dream states, and because in our most natural form of understanding we are, or tend to be, as freely perceptive as we are when we listen to music, it can be derived that the fluid nature of human cognition is infused by the work of our memory totally and unconditionally.

Therefore, in all forms of receiving, a visitation into a similar pattern filling up our mind is sensed and required in turn. For this reason, I propose by guidance a method of analysis which I call in this paper 'Clock-ability' that answers almost all questions originating in and from the memory if one sets one's analytic mind on the right angle of view while inquiring into layers of knowing.

---
---

### Clockability

![Clockability](https://github.com/exbuddha/Solar/blob/master/doc/img/Clockability-1.png)

**Clockability:** Scientific apparatus for measurements in human perception of memory and the inter-relations it creates by expansion in the way nature intends. This is the most natural language for music theory and analysis.

Along the main approach to solving all problems in music theory, such as representation of notes and intervals, all commonly known conversions among them, chord naming and conversion, and phrase detection, there are three forms of entities or data types that are introduced in the context of any progressive step-wise spectrum or range in music theory:

  1. Progressor
  2. Regressor
  3. Templator

Progressor is the super-type of the two. It represents an "open known" differentiating amount of progression. It is generally relaxed on the notion of direction of progression, such as chord interval progressive units like m2, M3, aug., dim., 4th, 5th, etc.

Regressors are the well-known progressors that are closed in their effect with the differentiating amount, such as flat, natural, and sharp accidentals. (no openness in direction)

Templators are the most complex of the three. They extend progressor units to cover all change forms in progressive detection as complex as memory/thought units or visual vectorized units that can aid a robot in detecting perspective among objects in vision. They intend to have no limits in definition of their units, therefore are the best subjects for mathematical formulation in infinitely large continuum or fields. Musical octaves are an example of what a templator can represent.

![Axes of Musical Analysis](https://github.com/exbuddha/Solar/blob/master/doc/img/Clockability-2.png)

It is important to remember that the definitions of Regressor, Progressor, and Templator are all respectively set on the scope of their elements within specific functionality. So, an element can be a Templator in its main/immediate scope and be a different one (Regressor or Progressor) in another scope. This explains, in essence, the purpose for the statement of "setting one's analytic mind on the right angle" at the beginning of this paper.

Below, I will recapture the knowledge of the system of music progression, as shown in the Java interface [Clockable&lt;T&gt;](https://github.com/exbuddha/Solar/blob/master/java/music/system/data/Clockable.java) in the included source code.

![Clockable System](https://github.com/exbuddha/Solar/blob/master/doc/img/Clockability-3.png)

**Element:** the most basic unit of data in the domain of clockable systems.

**System:** a collectively meaningful system of elements with arbitrary degree of complexity.

---

**Elementary:** the defining operative for relations that are in the most simplified form.

**Complex:** the defining operative for relations that are not elementary all the time.

**Definitive:** the defining operative for relations that are with no degrees of freedom.

**Undefinitive:** the defining operative for relations that are with some degree of freedom.

---

**Regressor:** the simplest well-defined normalized bit of data in clockable systems.

**Progressor:** the next well-defined non-normalized bit of data in clockable systems.

**Templator:** the most freely defined bit of data in clockable systems distinct from the two.

---

**Regressive:** the defining operative for cognitions and conversions that are the most restrictive with respect to their two-dimensional elements.

**Progressive:** the defining operative for cognitions and conversions that are the most expansive with respect to their two-dimensional elements.

**Templative:** the defining operative for cognitions and conversions that are totally free with respect to their n-dimensional elements.

**Systematic:** the defining operative for cognitions and conversions that are system-based with respect to their progressive elements.

---

**TemplativeRegression:** tabular three-dimensional functional systems that are restrictive in nature.

**TemplativeProgression:** tabular three-dimensional functional systems that are expansive in nature.

**Regressional:** conversional operations that expansively accept a regressor and a free object.

**Rotational:** axes of regressors, as simplified/linear systems that support restrictive data forms.

---

**Pendular:** attribute of axes that resemble motion of pendulums.

**Spiral:** attribute of axes that resemble motion of spirals.

**Sinusoidal:** attribute of spiral axes that resemble repetitive motions.

**Clockable:** attribute of all rotating axes of data.

**Convertible:** attribute of all axes of data that are on a continuum, and therefore convert.

  * All interfaces defined above, specially the templative functionals, are designed to reduce all complex operations into sets of well-defined one-way (normalized) tabular conversions that aid in organizing any system of relative inter-related knowledge, such as music theory and any other scientific system, with the aim of opening doorways to formulate and study them.
  * Remember that both TemplativeProgression and TemplativeRegression reflect or describe a space with functional ordering where the first generic type is for the items in the space, the second is an amount, and the third is a known unit.

---
---

In the following chapter, I will include excerpts that depict a large-scale view consisting of scales, intervals, tones, and forms which will aid the mind in understanding and explaining the most fundamental underlying thought forms during listening to and exposing oneself to music. These high-level concepts will help you in understanding your hearing process and in paving a defined path to the formulaic approach for the design of an ultimate music analysis system.

Knowledge of music theory and having an active image of the ideas constituting it is required in order to understand the next part of this paper clearly. Up to this point, the definitions presented are quite vague and abstract. They require to be re-read over and over again and pondered upon fairly deeply for their conception and their emergence through the recursive thought-patterns they aim to formulate. From here on, the language of the paper will change to a much more natural one, making the connection to the previous part somewhat invisible. In attempting to explain this disconnect in ideation of the content above, it is important to remember that the work of formulation of music theory and analysis is renewing and under design. As progress is made slowly in finding answers to document such effort on paper in a scientific language, more functions will be included in the higher level interfaces explained up to this point or thereafter. However, this does not invalidate the content presented in the following chapters. The statements presented forth all originate from natural observations on the processes involved during listening and emotionalizing music and speech. For this reason, they are more personal or perceptive and less universal or logical. Connecting the two forms of expressions is a work trusted to the interested reader.

---

### Musical Hearing

At some point in our long history in the universe, we have become sufficiently aware of sounds as tuned sensations. Either through hearing the birds chirp in wildernesses or the tree branches creak as the wind force moves through them; one way or another, we internally became sensitive to the tone quality of sounds as we now call them pitch, timbre, or tone. As instruments were made with the material we found in nature, one absolute constant became clear: that musical pitches are sensed singularly in repeating tiers and therefore can be grouped in what we now call octaves. This awareness grew over time further to the point of discovering the standard twelve notes or the eleven intervals, the selective scales, harmonies and chords, and all forms of conversions that are now discussed in what we call the music theory.

The sensations have always been present in nature. We now only know them as symbolized units that have names and, at the same time, show universally accepted properties that are formulaic. The three types of information, or thoughts, derived in the approach are again free on the axis of duality, loosely implying that there are more than one way to overlay them on the context of thoughts regarding scientific thinking. The two main contexts of interest are music and memory.

**In the context of memory:**

  - Regressor is the mode of thinking that brings memory of past events.
  - Progressor is the mode that allows focused thinking on the subject of presence.
  - Templator is the mode that settles the mind down and allows renewed thoughts to enter the mind.

**In the context of music:**

  - Regressor is the element that is strongly set or defined, similar to accidentals.
  - Progressor is the element that is two-way or loosely existent like intervals.
  - Templator is the third and isolated kind differentiating from the two, similar to octaves.

Note that it is fundamentally in the knowing that octaves are similarly sounding that all the other contained pitches find their meaning. As such undeniable influence exists among everyone with healthy ears and hearing ability, there are many other fundamental ideas that are deeply rooted and always present within the analytic mind that cause us to feel a certain way toward musical events. These ideas are very much present within our perception of the external world and they all originate from one or another fact that is eternally present in nature as we live and see them all the time. They are so fundamental that they sometimes have presence, or an equal presentation, in the world of numbers as well. For example, there is an undeniable knowing within all humans with healthy thinking minds that the number two is made up of addition. It is always naturally derivable that two number ones generate the number two. This fact resurfaces every time our mind discerns two distinct sounds in music. The sensation of this reality is totally different from the mathematical knowing of it. Yet it is still true. We only feel two sounds more presently in music. We also inherently know that the number two is larger than the number one. This fact also exists whenever there is the perception of two distinct sounds in music. It is for this exact reason that we tend to get carried away by two melody lines or that we desire the experience to continue for longer. Two voices carry a larger assuring sensation than a single voice. The play of intervals and subtle motions within them is also more pleasant, but the latter fact is no where to be found in the world of mathematics. Generally speaking as musical events reach fullness in their tone and the number of distinct units perceived, our experience of time becomes more heavily centered within ourselves. The human mind has a tendency to want to understand meanings through the words that are heard during speech. The same tendency appears when musical events occur and the more voices are present the more challenging the process of understanding becomes.

On the subject of perception of rise and fall in music, there must be clarity in remembering that humans perceive low-band frequencies with less effort on attention than the high-band tones. So it can be said that the lower tones leave a more soothing impression in general. The abruptness or the loudness in any tone creates low-to-high immediate attention pull, therefore the high transient sounds tend to drop one down immediately after they are emitted and received, creating disruption in the heart, and the lower tones create a more grounding fear setting one down and keeping one there as they generally are less disruptive to the heart. Rhythm is completely related to tempo with respect to its effect on the memory of the heartbeat but is still under the similar low-to-high rule of perception. Therefore, the lower rhythmic sounds are more pleasant and control the heart rate more naturally while the higher rhythmic sounds generate disruption in thoughts easier than the experience of feeling the heartbeat.

Human perception changes from one moment to another based on the current moods and memories. The mind is just like an instrument. It tunes, just like instruments can, as soon as the music is received. The voice of intention works in this manner: "if it is not speech it must be given musical attention to," and therefore the mind tunes in on the natural sounds. This, in turn, continues the experience of listening over time as the mind follows each element it sees or recognizes in music initially, just like listening to speech. Natural sounds are more pleasant in general because they have been heard overly in nature.

Vibration is perceived as changes in intensity, therefore it resembles the effect of rhythmic sounds, except that it connects more deeply to the memory of the past melody/phrase for that specific timbre, whereas rhythmic sounds lack in the effectiveness from timbre over time and are more involved with the heartbeat. As the pitch of vibrating sound becomes closely centered around a single pitch the sensation of music resembles that of human speech and, as a result, creates a more present emotional connection with the belief of realness or purpose.

Harmony, doubling, choiring, reverberation, echoing, or chorusing are all definitive of the surrounding. So they create sensations of the space and the place sounds are originating from leading quickly to bringing the attention outside of the space of natural/normal thoughts. They are immediately connected to the notion of depth in the trails of thought.

Distorted sounds fall in the category of abrupt or transient ones with the addition of extending in time and therefore immediately take on the role of timbre-governing sounds once they are received. They have a more intense effect on the memory, more so than natural/soft sounds.

Raising tempo can create excitement in rock 'n roll tunes.

It is very interesting that the pentatonic scale is so popular because of the certain effects its structural intervallic design brings into consciousness where other more verbose (in the amount of intervallic variety) scales don't. Because there are only five active notes present in the pentatonic scale the mind and its tuning/filtering faculty renders certain emotions or perceptions that are unique to that scale. This is, again, because of the lesser number of intervals that the scale features. Music written in such scales starts to sound more and more basic and some fundamental properties within the intervals surface easier and memory allows them to be heard or picked up quicker.

This explains why half-tones, or in some cases full-tones, that are outside of the field of expectation (during listening and after tuning of the mind) sound and feel more emotionally potent. The consciousness either enjoys those quickly picked-up anomalies, producing enjoyment in grief or excitement in subtle playfulness, or dismisses them as disruption in the flow of natural thinking.

---

For humans, everything emotional in music is related to a memory based on, or basing one in, a state of consciousness that brings forth the notion of resemblance. The beauty in musical tones, passed the point of interval sensations or rhythmic excellence, is originating from memory. The memory of man with regards to any artwork is rooted in seeing/recognition of similarity to a past event (in the artwork itself) or in outside incidents (with respect to objects outside of the artwork).

After the mind latches on the tones heard in a musical piece, the appeal that shines in the excellence in coupling sounds (to create harmony and order) comes from the same two sources. Two melody lines that clearly complement each other and not so much other incidents in the song are brought into attention/focus due to the similar pattern of thought (hidden to the mind at first) described/depicted above. A bass line and the rhythmic section share many interesting conjunction points. They are both outside of the normal/speech ranges of heard sounds; one brings in continuous attention related to the heartbeat and the other brings in the memory of speech, meanings, and feelings present or attached to past times. They have excellent counter-relationship. Two melody lines appealing to one another do the same, only on a different aspect line of thought. They, being closely similar in tone quality or in timing/timed effects, generate more completeness in the space of intentions or meanings and the beauty in their sensational quality is always rooted in the musical relationships their mutual and individual incidents generate in memory, more so regarding the past events in the artwork itself than the earlier example explained. As the instrument sounds become more and more human-like, their perceived beauty also becomes more and more relating to the qualities found in resemblance to human speech, meanings, and story tellings. Human voice stretches. So do string instrument sounds which are performed by fingers directly touching the strings, or by tube instruments. Three notes played quickly with respect to each other create their effect purely based on whether there are rises or falls involved in generating the melody they create over time. The sooner an incident (a rise or a fall) is witnessed the more prominent its effect on finishing that line of thought (phrase or sub-phrase).

It is many times during listening closely that whenever the movement of melody in a phrase traverses over a tightly closed interval relative to the entire intervallic mood (key and chord), as in stepping up and down by half- or a full-tones, the opposite directional movement in that case carries qualities such that when the original melody is repeated again, or is complemented, then the rest of the phrase brings in a taste that is pleasantly felt. Similarly so, there is consensus among composers that when sub-phrases become more densely centered around closed intervals the memory forms a habit of wanting to hear a similar relational occurrence among tonalities that will be remembered from the earliest available point in memory.

These higher truths make up the most interesting views on music that one can relate personally and impersonally to beauty in art forms: the deeper less visible thoughts relating one to similarities or singularities in the collective mind, definitely originating from external and higher causal planes such as poetry.

Two notes creating harmony and the twelve tones constructing the entire note table are perceived also by the mind fixated on the sensations of hearing and the pleasure it elicits in the sensational part of the human mind. These constants in music are truths just like other truths that are undeniable and inseparable from the timeline, history, and many experiences of hearing music. Above that point, everything can be explained by the phenomenon of singularity in the mind.

In any three-note sub-phrase where only the second note isolates the two similar beginning and ending tones, such as a rise followed by a fall or the opposite incident, the underlying perceived effect is of articulation or variance. This is specially so when the three-note sequence, or series of reoccurring sequences, leads to an ending tone of a sub-phrase or full phrase, making the relation between the previous incidents, very likely the beginning of the phrase and the final resting tone, of the highest value and importance during analysis.

![Articulation](https://github.com/exbuddha/Solar/blob/master/doc/img/MusicalHearing-1.png)

One firstly is aroused by the inherent aesthetic quality within the sonic playfulness in music - the appeal in tonal qualities, and secondly gets a chance to come down to memory. This form of being when listening to music defines the basics of healthy attentiveness or being totally absorbed in music. It is in this state that music feels holy and starts to speak to the soul or the spirit. The aftermath of these experiences then can be perceived or be brought down or explained by perception. That form of explanation (thinking) is rooted in singularity - being completely involved in the act of listening within the mind and the subtleties that memory speaks in: similarity, uniformity, or remembrance. At that level, the speech directs to the facets of uniformity that appeals to one, personally and similarly fathomed by same kinds. There are obstacles in recognizing these appeals clearly and in finding truth in them, just as there is blocks in vision for every person with regards to understanding or seeing higher truths. One such obstacle is prejudice.

---

Evident in alignment with this form of analysis and understanding of music is the many subjects relating to perception in the presence of musical hearing. One of these is that continuing on the realization that everything about perceiving music has to do with memory and is connected to memory in humans, a very clear fact is that any instrument sound (or any music part sound forming an individual unity that translates almost always to one instrument) is connected to a memory that originates from sounds that are already heard. They could also originate from visions but those types of perceptions are much harder to understand and connect to sound, therefore it is very easy to see how instrument sounds have a relation to memory through other sounds that have been experienced in the past. For example, the sound of instruments that are stringed but don't freely offer the sensation of sustain in shifting pitch, similar to the guitar, the piano, or the dulcimer, have a very clear relationship with the sound of birds or the chirping sound that they make. One could extend this to other forms of animal sounds but this one specifically is very obvious. Another one is that the pad sound, the sound of strings section or electronic pads that are very soft, either made up of wind instruments such as the trumpet or of stringed instruments like the violin or the viola, have a clear relationship with the atmosphere. When these types of sounds are given a little amount of reverberation due to the accompaniment that usually is present, the sensation of wind or the atmosphere is very strong in hearing.

Another realization is that when the spirit enjoys or when the sounds or experiences that rise from music are pleasant, this means that those sounds are activating a memory point that is enjoyable. In such cases, the experiences present in vision are very much related to the experiences in hearing. So, if one person is sitting by the water and notices how beautifully balanced the water moves in the landscape just enough that a little amount of water travels over the steps, giving the sensation that the soil is being calmly nurtured, such typical visions hold up a very clear memory point that sounds of instruments in music as a whole can elicit easily; and depending on whether that memory is a pleasant one or a non-pleasant one, the spirit will enjoy, will invigorate from it, or will drop down to a state of unrest. Therefore, in effect, considering the entire subject of musical experience, as a whole, musical incidents have the property of fixating on memory points. I discussed here the pleasant one and the unrestful one but there are a number of other types of feelings or emotions that are fundamental to activation of memory points. Any of those can be fixated by music, and that depends on tone qualities, harmonies, tempos, changes in music, and melodic constructions.

Logically speaking, because of the fact that all humans who have a decent amount of perception of harmony and of their hearing abilities regarding music and tones and pitch specifically will consider, at any point in time, the unison interval or an octave both as having the same pitch quality, the same awareness of similarity can be extended to find other intervals as well: the fifth, the fourth, the third, and the seventh, and so on. Every sensation or influence that intervals and harmonies create can be derived from the fact that the unison and octave have the same exact effect.

---
---

In the following chapter, I will present a more logical description of the content explained up to this point in a scientific language touching on ideas related to music theory that can aid you in understanding how phrases are detected by code and how the described sensations are elicited through changes in tonality.

---

### Musical Expression: Phrase Deconstruction and Detection

Given the complexity of representing the knowledge of musical hearing in logical terms, for the immensely numerous forms of cognitive relationships that exist in the way of making such logical units of thought present, in finding an optimal solution to the problem at hand a direct involvement of human intelligence is reluctantly accepted. At the end of this chapter, I will return to this point again and explain more clearly how this task can be organized in code.

In an effort to define the formulas in a logical language, I, as well as presumably many others before me, have followed the same pattern of expansion from notes to intervals, to chords, to scales, and so forth as you can find in the sample code inside the package [musical](https://github.com/exbuddha/Solar/tree/master/java/musical). This package contains many classes that represent the entire knowledge of music theory. Most importantly, in order to bring more clarity to the process of defining scales, chords within scales, and phrases that scales support or allow by aesthetic evaluation, new terms have been created and given meaning to within the [Scale](https://github.com/exbuddha/Solar/blob/master/java/musical/Scale.java) class of the mentioned package. Among these new terms the two most important ones are [Range](https://github.com/exbuddha/Solar/blob/master/java/musical/Range.java) and [Pulse](https://github.com/exbuddha/Solar/blob/master/java/musical/Pulse.java) that reoccur more than once. They each have their own unique functional presence within the [musical](https://github.com/exbuddha/Solar/tree/master/java/musical) package and another classified presence within the [Scale](https://github.com/exbuddha/Solar/blob/master/java/musical/Scale.java) class. These two new data types both have self-sufficient and non-overlapping definitions within the project; however, the meanings that their names carry can become confusing if not fully understood and accepted. After spending time reviewing the classes in the mentioned package and becoming comfortable with the terminology presented in those classes and their sub-classes, the following sections will inform the reader of a process of phrase detection and musical analysis that can definitely be translated into code and eventually generate accurate results as humans perceive music on the plane of emotions or feelings.

[Range](https://github.com/exbuddha/Solar/blob/master/java/musical/Range.java) classifies spectrums in music emphasizing a set of selected frequencies from a larger spectrum, with arbitrary degrees of freedom from the time and/or the pitch axis. Scale ranges are simplified representations of sonic events, geared to describe phrases, and sub-phrases, in an event-driven mesh of data, similar to a graph structures, that compress forms of activities present in the aural space. Each scale defines all of its degrees, or the notes consisting the scale, as ranges. Therefore, the simplest form of range is a single tone. As the number of tones grow in phrases in a certain scale, or multiple scales, more tones can be bunched up in a single pulse.

[Pulse](https://github.com/exbuddha/Solar/blob/master/java/musical/Pulse.java) classifies noticeable expressions in sound synthesis and music. It can be simply defined as the most basic form of tonal quality, whether it is a single tone or a harmonized group of tones. Pulses are musical incidents or events that each note in a musical score stands for. They can be combined sequentially over time in order to generate phrases or sub-phrases. It is important to remember, again, that in this design there is no time information recorded within pulse or range structure. The closest bits of information to time values are the compressed and simplified forms of events that are attached to every tone within a range. These events, similar to the standard MIDI events, aim to define relationships among individual tones within ranges or parts of them. They can provide a good background to make up phrases from simpler units they contain and to provide algorithms with  an "easy and simple to decipher" data packs for sensitive musical interpretations. Below is a picture showing a sample range and its contained pulses.

![Musical Range](https://github.com/exbuddha/Solar/blob/master/doc/img/MusicalExpression-1.png)

The exact tonal information that each circled number in this full range stores is listed below.

  1. Tone 1 starts normally.
  2. Tone 1 continues normally.
  3. Tone 1 continues shortly. (or stops quickly)
  4. Tone 2 starts normally.
  5. Tone 2 continues normally.
  6. Tone 3 graces tone 1.

A few points to note in this description is that there is no "stop" information stored in the paradigm of the range and that the recorded information is always forward-looking implying that note stop points are automatically discerned. Also, it must be evident how a small number of events and connective attributes can cover a large number of possibilities sonically maturing ranges into phrase-like data types. There is no time information included as mentioned earlier. This form of recording enables shifting the window of time freely which is a desirable type of interpretation in all phrase detection algorithms. For instance, because of the shortness property of the grace tone 3 (depicted on the left) there is a new line of hearing that translates to a quick stop as depicted on the right by the horizontal line number 3. In effect, tone 3 can be considered as the continuation of tone 2 inside the third sub-range; therefore, when timing information is present or added to the full range, this bit of data becomes crucial for correct evaluation of the sonic effects in music.

Finally, tone 6 is marked as grace note with respect to tone 1. This implies a new form of recording that inter-relates two or more tones with each other. This information type is called 'appearance' while the former depicted type is called 'stretch'. Note that a stretch is applied only to similar tones that reoccur within two adjacent sub-ranges forming a natural continuation in music. An appearance, on the other hands, connects two distinct tones within the same sub-range or adjacent sub-ranges forming a slur in music. It is physically impossible for two stretch connective types to exist with similar starting tones.

---

When note groups in a score part become aligned in such a manner, as shown above, then their inter-relations are categorized such that they will provide the ground for making intelligent decision makings about the effects on cognition. In other words, this form of deconstruction of musical phrases forms the basis for both categorization and detection of phrases by comparison.

The relations derived from the data captured in scale ranges are purely based on concepts of harmonization, modulation, and frequency characterization. Harmonization and modulation are effects that create pleasant or unpleasant feelings and are purely based on the numerical relationships that frequencies and their numerical (cyclic) values have. Modulation creates additional heard frequencies that add to the effect of notes that are active within pulses. Ranges can be grouped in scales, depending on the pleasantness or unpleasantness they create in the sensational memory, while modulations can increase the complexity of this grouping. Modulation occurs naturally as notes fall in frequency bands that are closer to each other and at certain distances they become ineffective and start to appear more so as separate tones than mixed (modulated) tones. At that point, they fall in less definitive intervallic characterizing groups such as thirds, fourths, fifths, etc. Even these forms of harmonized tones can be said to have heavy modulating effects. It is after the perfect fifth interval that they start to slowly separate out and between the seventh and the perfect octave, they are fully distinguishable. Remember that many close intervals show a two-way effect depending on the instrument sound and the tone qualities of accompaniments. There are many times a slight amount of fourth heard in the perfect fifth intervals in stringed instruments such as the violin.

As intervals grow apart, the change of tones or their frequency difference becomes larger than the amount that appears in the more closely coupled modulating effects, so they start to sound more like two separate lines of melody rather than a mixed pulse. As the number of notes in a pulse increases, this becomes more and more complex because the number of separate tones creates feelings that are different from the simpler cases such as two- or three-tone intervals. The natural logical process of discerning emotional effects in musical expressions is always from notation to pulsation and range definitions, to detecting harmonization and modulation, to feelings and sensations. Whether this is done by involvement of human intelligence or purely computationally does not change the flow of movement in this form of analysis.

From this point on in the chapter, I will refer to harmonization and sonic modulation both as 'modulation'. The reason for this is that the word modulation actually has a presence in scale changes that occur in classical or traditional music. The two forms are in fact connected but are differentiated on two differently scaled ranges of spectrum; nevertheless, they are exactly the same in a higher plane of thought. So one word explains both effects.

Proximity of tones and their frequencies inwardly defines lines of melody as lines of thought. Memory of them added the feeling that intervals and ranges of the two create arouses the desire to rest in place or move on to a new place in thoughts. This constructs the basis of hearing melody lines. Tonality and scale set the base for these forms of motions. The lowest tone or the lower tones respectively to the higher tones set a different form of sensation. Higher notes give definition and attract more of the cognitive energy or focus. Lower notes create and change tonality, scale, and the overall, or more persistent feelings. There is something in modulation of lower notes that feels more directing and persistent. They change; the overall feeling changes. This is not so much strong in the higher melodic notes. They change; memory of them and the flow of the movement in the line of melody changes. The work of lower tones in memory persists longer. Higher tones' work in memory is forgotten or given in to the flow of thoughts more rapidly. Activity in each band or range (low to high) grabs the attention over time so the mind tunes in and becomes focused on that area more  and more as time of activity increases. Sound of instruments and their quality plays a big role in expectations of what should be considered low and what should be considered mid or high.

![Musical Bands](https://github.com/exbuddha/Solar/blob/master/doc/img/MusicalExpression-2.png)

The picture above shows a few sample ranges from a typical song performed by the guitar or the piano. These arrows constructed on the basis of proximity of intervals and tonality (scale-related pleasantness or unpleasantness) and scales are a matter of activity and memory residue during listening. The more pleasant activities match certain scales or modes; or the more memory of such activities occurs and persists the more that scale fits in logically and aesthetically. As tones bunch up more, the proximity effect among them becomes more prominent and dominant. The pleasant ones give more rest and the unpleasant ones give more unrest or create tendencies to move elsewhere. As the tonality becomes more defined the relative intervallic distances become more determinant.

Each instrument has a global low, mid, and high range. Each change becomes more determined by this relative determinant factor, so the proximity affects memory more clearly and gives rise to the sensation of melody lines. Different instruments clearly are less prone to being mixed in this calculation and form their own proximity sets, but they affect the overall sensation that is more purely intervallic and scale-defined, because the memory of tone quality of sound is extremely dominant. Therefore, each instrument justifiably so belongs to its own memory line just like it belongs to its own score part. Memory actively pursues tone quality. Tonality or scale inter-relativity is purely a matter of intervallic calculation and it is highly related to loudness or presence or intensity of sounds.

Each phrase calls for the next. Some rests allow stoppage.

The memory of activity plays a higher role in resolutions. So, if two instrument tones create unrest or unpleasantness, the more active one is expected to have caused and to be the one to resolve it. Higher pitches are given more precedence in activity because of their natural ease in hearing range placement and tendencies to be selected as the dominant sound. Therefore, two low and mid-to-high instruments are viewed as the low being the less active but more tonality-dominant (creating or setting moods) and the mid-to-high being the more active and melody-dominant (creating flow and memory or phrase sensation).

Activity in one instrument or range means more changes in pitch over time. Beats are always purely active due to being both transient and generally high-pitched. They dominate awareness unless there is an active and highly present melody accompanying them.

Therefore, with design in mind, ranges are musical scale-specific data forms and pulses are model-generated (based on the score data) sampled data forms. As a scale becomes more and more comprehensive with range definitions as songs are committed to it, it becomes more and more possible for pulses in that scale to hit or find matching ranges that describe the tonal characteristic. Ranges deal with tonality of note sequences. Pulses deal with the breakdown of tones in humanly recognized chunks in order to locate the best fit that describes the rests and unrests in musical expressions: points of turn or meaningful conjunctions. Ranges rely on expansion based on rules of tonality and feelings or sensations they elicit. Pulses rely on time effects (or effects of timings) based on rules of music listening and interpretation. Pulses are generated by the conductor's execution model in the code or by the instance-based data that each score provides. They then couple with ranges on a match-based criteria system to examine sensations more closely. These sensations then define effects on memory to define the overall feel of songs and their parts.

Eventually, the laws of sensation can be expressed in human logical terms.

---

On the subject of phrase detection, sensation, and work of memory in perceiving music and emotionalizing it, one true fact is that in all movements of melody the raise or upward movement of pitches will also raise attention and awareness, most relate-ably due to its upward energy in expression to higher attentive bands while the fall or downward movement of pitches will settle attention down due to the opposite mark it leaves on perception during listening.

The memory of tones explained by tonality rules and scale truths (laws) remains throughout all forms of music listening but this rise or fall (truth) also is always with the involvement of human perception in the form of the question "what's to follow next." The beauty and the meaning is expressed in tonality and the dance that notes, in sequences or combinations, play out over time. The mood is set by the sound qualities that are present (in line with emotions of the moment), and also heavily by activity in musical melodies and incidents such as tempo and repetition rates. The overall movement of attention energy is ruled by directionality of tones, upward or downward. Of all, the most mysterious work is the work of tonality because it ties to human memory so strongly. As Victor Wooten mentions in his book, The Music Lesson, how moving one note up or down by a half or a full step can turn the expression to a pleasant one if it already is not, the tonality of scales and the sensations they imprint and leave in the memory of melody lines is the most interesting. The distances between consequent intervals, along with the memory of the past sensation that is or was present in the melody line makes up the laws of scales (tonality). The emotions emerge with the melody personality depending on human expectations; however, the emotions also fall in categories of major and minor. They seem to be mainly controlled by presence of modulations and the placement within bands and instrument ranges of sounds, where modulations emerge with respect to what has already been modulated to the emotional space of perception. Note that how when by shifting tonal awareness scales change and merge into one another, also the mental perception in listening so drastically changes the scenery. This is the same major attention-grabbing incident (larger than tonal shifts of melody line with the familiar established scale) that shifts or allows change of emotional mood according to the human listener's disposition within his or her own personal space which is entirely memory-driven. The awareness of scales is brought into the mind and the hearing perception by the phenomena of tonal modulations that already exists between groups of tones (scale ranges). How they move and where they change into is the property of listener's memory line (of thoughts) that connects personality, although not entirely chaotic, to emotions.

The pleasantness and unexpectedness (unfamiliar new modulations) and unpleasantness create beauty, in all forms: happiness and captivating (major) or sorrowful and mesmerizing (minor) or mystifying (pentatonic). Note that as tones in scales grow apart in intervallic distances, their emotional property slowly changes from personally affecting to neutrally present. Major and minor are themselves because of the slight shift in tonality of the third interval and the connecting of the sixth to the seventh interval. The seventh to octave is always the resolve and it carries a very strong sensation in forward scales. The opposite is true in backward scales. This is much less present in five-note, four-note, and three-note scales. By three-note, we are touching the sensational plane of chords that are very open and have the property of fitting to other more expressive scales in order to bring out much more complexity in the tonal modulation in order to create much more elaborate moods in the human listener's perception. This is how music affects us and feels.

The extent of modulation becomes effective with two notes (harmony). It extends to three and four note incidents (chords) which becomes much more memory-based leading to the perception of tonality (scales). From five to nine notes, the knowledge (or the familiarity) of scales becomes fully matured. Scale movements and the effect of melody in time through memory becomes more prominent than just the tonal modulation rules and it (melody line) also becomes heavily involved in emotional memory within the modulating space of chords and tones (bands): mood formation.

Timing and rhythms are essentially and entirely connected to moods. They affect the language of the heart, as they are solely and purely involved in beats, a matter of the heart-attention.

Timbre or instrument sound quality is purely a matter for selecting mood. Therefore, it is completely emotional.

The work of memory in melody line, connected more strongly to line of thought, is involved in sensation of repeating (or heard) tones, closely resembling memory of language, speech, and therefore meanings. Its expecting factor has to do with the expectations that rise in modulation of tonal pathways. The work of memory in tonal quality (scales and harmonies) deals less with that aspect of perception and is more involved with sensation of tones and their modulating aspects (mood). Coupled together, one works through another: the melody line is sensed through the mood or the atmosphere. Pathways are created by the expectations and the memory of their sensations through the tonal quality in what is present (mood) and this creates the future aspect in listening to the melody line. Conversely what becomes heard and experienced becomes a part of the memory line which gives rise (or way) to sensations in memory of repetitions and their familiarity. The beats, therefore, are purely memory eliciting. Their alignment with expected melody lines emphasizes the memory of repeating emotions and their misalignment separates or frees awareness from this repetition.

---

In perceiving tonality, I established that memory and activity play a big role. Extending this statement more, the similar rules work during application of tonality. When more than one tone is harmonized, human attention is focused firstly on only one tone and the others work through that one base tone. This is how intervals and chords are perceived. Of course, there is a lot of personality playing into this rule since one mind can focus on a certain tone while another mind might pick up a different base tone upon hearing the same harmony or interval. Aside from the personal aspect, there are methods for assisting the mind in perceiving a certain tone first over others and that is the gift of sound engineering and music analysis. Loudness, slight timing differences, tone quality, and comforting bandwidth are all examples of these methods of song construction and playback. What the line of thought focuses on most becomes what the expectation will hear next.

While there are fewer expectation rooted in a listener's mind, for reasons such as less seasoned affiliation or encountering unheard musical tones, the mind works less in the mental plane of expectations of tones that are to follow. The residue in the perceptive listener's mind will form sensations based on the more fundamental experiences of listening such as the rises and falls, the rests and unrests, and finally the pleasantnesses and the unpleasantnesses. At the final stages, the mind has already formed expectations due to repetitions and getting accustomed to sound qualities. The meanings of tones and melodies will then change to something more cemented and the repeated experiences of listening to same or similar music will be purely based on the past habits forming those experiences. The music listening becomes less and less surprising and body-driven and more and more memory-driven and judgmentally sided. The original sensations fade into the new memory-driven remembrances. The listener is under the conception that he or she is now a seasoned listener.

If one can entirely forget music, styles, or sound qualities or tonality, one will hear and re-experience music like the first encounter. For this same explained fact is that the collective is the best judge available in listening and judging the sensations in musical pieces and that tonality becomes meaningful in scales "per song."

---

Now, I will return the focus back on the beginning of this chapter, where I mentioned that there must be a systematic way to incorporate human intelligence in the process of phrase detection and cognitive analysis. If the reader expands on the ending term of this chapter - per song, then it will eventually become clear how every song must inevitably become a data point for all other forms of data that were introduced in the chapter, such as ranges, pulses, sub-phrases, etc. Because each song, or musical piece, has a certain musical mood inter-connecting to its key or chord progression and many other characteristics, some of which were discussed in details but rather briefly also, any data that is brought within music analysis systems by human involvement must be tagged with that specific song.

Songs can be quite easily related to many other forms of perceptive judgments about their nature or their influence on human sensation. This makes them the only right choice for extending such perceptions to similar works of music. As the number of songs in a system grows and as the amount of perceptive data adds up along with those songs, it becomes more and more clearer how to implement relational properties that can speak or generate human-like decisions about the nature of new additions to that system. For example, when a new classical piece becomes available and is tagged with enough intelligent characteristics describing the feel and mood of the piece or its sonic arrangement, then the process of match-making for finding phrases and their sub-phrases starts to limit down logically into a set of well-defined methodologies. This, of course, will only be possible if there already exists at least one similarly tagged piece of music in the system that can provide a template for performing such high-level intelligent work. The details are, of course, open for discussion and research but the overall picture must be clear to the reader at this point.

---
---

In the next chapter, I will open up the subject of music performance in much detail and will present a complete logical workflow for generating performance instructions from a musical score by the use of computational and well-defined units.

The performance rules have very little to do with sonic perceptions. They are completely a human logical property. However, they are very challenging in processing at runtime because they overlap in more than one or even a handful areas and require to be resolved. This of course means more (higher) rules of performance must be included, detected, and brought in. Technically, each acceptance or rule-match leads to selection and a new path in performance. This causes a very large number of paths to be accepted at each instance and adds more complexity to the execution graph (also called the performance graph); however, at some point there will be cases that will cause a path to become less feasible and this will help reduce paths by certain scoring and ordering logic.

The benefit of rules of inference is that they are infinitely expansible. This fits their purpose greatly. Laws and facts originate from physical rules of contact and motion, anatomical sensations and preferences, sonic preferences, instrument-specific rules of performance (the most determining and valuable one), and score demands (the strongest eliminating factor). Some of these are included in the change graph, which I will introduce later on in code, but essentially their existence is tied to rules of inference specific to human anatomical features and that of the instruments. Many others are exerted on available paths that are collective called preferences.

Stay tuned.
